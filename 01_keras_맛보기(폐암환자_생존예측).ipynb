{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_keras 맛보기(폐암환자 생존예측)",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ckXxFYjaGU4auv7CowQ6LIB56BTGaYzD",
      "authorship_tag": "ABX9TyMYqiojj5nhM7xKHE3lhhsu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gudals6676/Python/blob/master/01_keras_%EB%A7%9B%EB%B3%B4%EA%B8%B0(%ED%8F%90%EC%95%94%ED%99%98%EC%9E%90_%EC%83%9D%EC%A1%B4%EC%98%88%EC%B8%A1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE6inEWuAL8h"
      },
      "source": [
        "### 목표\n",
        "- 폐암 환자의 생존을 예측하는 모델을 만들어보자!\n",
        "- 신경망을 활용하여 2진 분류 문제를 해결해보자!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LhfGsjt9Y4-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "I-LxbCRWlu98",
        "outputId": "da50f691-7996-4123-d686-280b999c1f10"
      },
      "source": [
        "# header : 데이터프레임에서 컬럼명을 설정해주는 함수(None : 인덱스 번호로 컬럼명이 설정됨)\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/빅데이터4차_딥러닝/data/ThoraricSurgery.csv\",\n",
        "                   header = None)\n",
        "data"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>293</td>\n",
              "      <td>1</td>\n",
              "      <td>3.80</td>\n",
              "      <td>2.80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.88</td>\n",
              "      <td>2.16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>3.19</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>3.98</td>\n",
              "      <td>3.06</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>2.21</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>98</td>\n",
              "      <td>6</td>\n",
              "      <td>3.04</td>\n",
              "      <td>2.40</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>369</td>\n",
              "      <td>6</td>\n",
              "      <td>3.88</td>\n",
              "      <td>2.72</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>406</td>\n",
              "      <td>6</td>\n",
              "      <td>5.36</td>\n",
              "      <td>3.96</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>25</td>\n",
              "      <td>8</td>\n",
              "      <td>4.32</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>447</td>\n",
              "      <td>8</td>\n",
              "      <td>5.20</td>\n",
              "      <td>4.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>470 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0   1     2     3   4   5   6   7   ...  10  11  12  13  14  15  16  17\n",
              "0    293   1  3.80  2.80   0   0   0   0  ...  12   0   0   0   1   0  62   0\n",
              "1      1   2  2.88  2.16   1   0   0   0  ...  14   0   0   0   1   0  60   0\n",
              "2      8   2  3.19  2.50   1   0   0   0  ...  11   0   0   1   1   0  66   1\n",
              "3     14   2  3.98  3.06   2   0   0   0  ...  14   0   0   0   1   0  80   1\n",
              "4     17   2  2.21  1.88   0   0   1   0  ...  12   0   0   0   1   0  56   0\n",
              "..   ...  ..   ...   ...  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..\n",
              "465   98   6  3.04  2.40   2   0   0   0  ...  11   0   0   0   1   0  76   0\n",
              "466  369   6  3.88  2.72   1   0   0   0  ...  12   0   0   0   1   0  77   0\n",
              "467  406   6  5.36  3.96   1   0   0   0  ...  12   0   0   0   0   0  62   0\n",
              "468   25   8  4.32  3.20   0   0   0   0  ...  11   0   0   0   0   0  58   1\n",
              "469  447   8  5.20  4.10   0   0   0   0  ...  12   0   0   0   0   0  49   0\n",
              "\n",
              "[470 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg-sWhagmEID",
        "outputId": "26efdbd9-2311-4544-8e4e-59c04839ceb7"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(470, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb-4DEQyn0Bz"
      },
      "source": [
        "# 문제, 정답 분리하기\n",
        "y = data[17]\n",
        "X = data.iloc[:,:17]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BILNa8kDoEaB",
        "outputId": "4cc1201f-fb6d-4a07-cc60-90de271e3ed5"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((470, 17), (470,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-5mzAR7oKpC"
      },
      "source": [
        "c = data[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNHMmG61o6oL"
      },
      "source": [
        "#학습, 평가 데이터 설정\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF74GG4Io7-D"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state=5\n",
        "                                                    )"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL8cBhTHpy5n",
        "outputId": "1eac273c-ab6a-4ddd-c54f-02730af80c40"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(329, 17)\n",
            "(141, 17)\n",
            "(329,)\n",
            "(141,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqRzWny4qWXi"
      },
      "source": [
        "### keras를 활용하여 딥러닝 신경망을 구성해보자!\n",
        "- 1. 신경망 구조 설계\n",
        "- 2. 학습/평가방법 설정\n",
        "- 3. 학습 + 시각화\n",
        "- 4. 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8KJIyXEp6Kb"
      },
      "source": [
        "# 딥러닝을 위한 라이브러리를 임포트\n",
        "from tensorflow.keras import Sequential     # 신경망의 뼈대를 구성\n",
        "from tensorflow.keras.layers import Dense   # 신경망의 층을 구성"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tEghBT7qoSa",
        "outputId": "ea59099f-afee-4abd-83dd-58dd699745c3"
      },
      "source": [
        "# 1. 신경망 구조 설계\n",
        "md = Sequential()\n",
        "\n",
        "# 입력층 + 중간층\n",
        "# input_dim : 데이터 특성의 개수\n",
        "# activation : 활성화 함수를 설정(들어온 자극(데이터)에 대한 응답여부를 결정하는 함수)\n",
        "md.add(Dense(10, input_dim= 17, activation= \"sigmoid\"))\n",
        "\n",
        "# 중간층\n",
        "md.add(Dense(5, activation=\"sigmoid\"))  # 하나의 층\n",
        "md.add(Dense(3, activation=\"sigmoid\"))  # 하나의 층\n",
        "\n",
        "# 출력층\n",
        "# 출력층은 회귀의 활성화함수(linear함수, 활성화 함수 생략가능)\n",
        "# 2진 분류의 활성화함수(sigmoid)\n",
        "md.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "md.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 10)                180       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 3)                 18        \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 257\n",
            "Trainable params: 257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Af-kN3S090b"
      },
      "source": [
        "### 활성화 함수 : 자극에 대한 반응여부를 결정하는 함수\n",
        "- 회귀 : linear(항등함수) -> 신경망에서 도출된 수치값을 그대로 예측에 사용\n",
        "- 분류 : 딥러닝은 선형회귀 모델을 기반으로 하고 있기 때문에 여기서 도출된 수치 값으로는 분류 문제를 예측하기 힘듦\n",
        "  - 2진분류 : sigmoid 함수(0.5를 기준으로 0 or 1 분류, 0인지 1인지를 확률 정보를 통해서 예측) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaS5eyQps0pv"
      },
      "source": [
        "# 2.학습/평가 방법 설정\n",
        "# binary_crossentropy : 2진 분류에 사용하는 손실함수(비용함수)\n",
        "# -> 오차의 평균을 구하는 것은 MSE와 같지만 0~1사이 값으로 변환 후 평균오차를 구하는 방식\n",
        "md.compile(loss=\"binary_crossentropy\",\n",
        "           optimizer = \"SGD\",          #최적화함수 : 확률적 경사하강법 사용\n",
        "           metrics=[\"acc\"]             #metrics : 평가 방법을 설정(분류 문제이기 때문에 정확도(acc)를 확인)\n",
        "           )"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZV8kHs53NAz",
        "outputId": "1069d8af-c001-40fe-e9c9-2b74e919c328"
      },
      "source": [
        "h = md.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8414 - acc: 0.1459\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8078 - acc: 0.1459\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7781 - acc: 0.1459\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7507 - acc: 0.1459\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7256 - acc: 0.1459\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7032 - acc: 0.2067\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6823 - acc: 0.8511\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6631 - acc: 0.8541\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6452 - acc: 0.8541\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6295 - acc: 0.8541\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6151 - acc: 0.8541\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6018 - acc: 0.8541\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5902 - acc: 0.8541\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5786 - acc: 0.8541\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5684 - acc: 0.8541\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5584 - acc: 0.8541\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5489 - acc: 0.8541\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5407 - acc: 0.8541\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5325 - acc: 0.8541\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5254 - acc: 0.8541\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5184 - acc: 0.8541\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5118 - acc: 0.8541\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5058 - acc: 0.8541\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5005 - acc: 0.8541\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4953 - acc: 0.8541\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4907 - acc: 0.8541\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4863 - acc: 0.8541\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4824 - acc: 0.8541\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4789 - acc: 0.8541\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4752 - acc: 0.8541\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4716 - acc: 0.8541\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4683 - acc: 0.8541\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4652 - acc: 0.8541\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4622 - acc: 0.8541\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4598 - acc: 0.8541\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4573 - acc: 0.8541\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4549 - acc: 0.8541\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4529 - acc: 0.8541\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4507 - acc: 0.8541\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4490 - acc: 0.8541\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4472 - acc: 0.8541\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4454 - acc: 0.8541\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4439 - acc: 0.8541\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4425 - acc: 0.8541\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4411 - acc: 0.8541\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4398 - acc: 0.8541\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4385 - acc: 0.8541\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4373 - acc: 0.8541\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4362 - acc: 0.8541\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4350 - acc: 0.8541\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4342 - acc: 0.8541\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4333 - acc: 0.8541\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4325 - acc: 0.8541\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4318 - acc: 0.8541\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4309 - acc: 0.8541\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4303 - acc: 0.8541\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4296 - acc: 0.8541\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4290 - acc: 0.8541\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4284 - acc: 0.8541\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4278 - acc: 0.8541\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4273 - acc: 0.8541\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4267 - acc: 0.8541\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4261 - acc: 0.8541\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4258 - acc: 0.8541\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4252 - acc: 0.8541\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4248 - acc: 0.8541\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4243 - acc: 0.8541\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4239 - acc: 0.8541\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4236 - acc: 0.8541\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4232 - acc: 0.8541\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4229 - acc: 0.8541\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4226 - acc: 0.8541\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4222 - acc: 0.8541\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4218 - acc: 0.8541\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4216 - acc: 0.8541\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4213 - acc: 0.8541\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4210 - acc: 0.8541\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4207 - acc: 0.8541\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4204 - acc: 0.8541\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4202 - acc: 0.8541\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4200 - acc: 0.8541\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4198 - acc: 0.8541\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4197 - acc: 0.8541\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4195 - acc: 0.8541\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4193 - acc: 0.8541\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4191 - acc: 0.8541\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4190 - acc: 0.8541\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4188 - acc: 0.8541\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4187 - acc: 0.8541\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4185 - acc: 0.8541\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4184 - acc: 0.8541\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4182 - acc: 0.8541\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4181 - acc: 0.8541\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4180 - acc: 0.8541\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4179 - acc: 0.8541\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4178 - acc: 0.8541\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4177 - acc: 0.8541\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4176 - acc: 0.8541\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4174 - acc: 0.8541\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4174 - acc: 0.8541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "2W7OivmH3oBp",
        "outputId": "bb9f4d1b-922b-48a2-b301-37e0a35b4d90"
      },
      "source": [
        "# 시각화\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.plot(range(1, 101, 1),\n",
        "         h.history['acc'],\n",
        "         label='acc'\n",
        "         )\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdXAlbWV3Ry5",
        "outputId": "9bba0590-1640-4bc5-ca0f-0a5e29ef90e5"
      },
      "source": [
        "# 모델 평가\n",
        "md.evaluate(X_test, y_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4335 - acc: 0.8440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43354934453964233, 0.8439716100692749]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY3PDoD_4zUQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}